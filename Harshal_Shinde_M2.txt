1. Creating the Directory and putting the file in to hadoop and continue the work in hadoop
 hadoop fs -mkdir /unit/
 hadoop fs -put /home/cloudera/Desktop/TejasBigData/fwdudfs/heathrow.txt /unit/

2. Start Pig:

3. Loading and Reading in the data:
data = LOAD '/unit/heathrow.txt.desktop' USING PigStorage('\t') AS (year:float, month:float, maxtemp:float, mintemp:float, frostday:chararray, rainfall:chararray, sunshine:chararray);
	
4. Data Cleaning :

Datavals = FOREACH data GENERATE year,month,maxtemp,mintemp,frostday,rainfall,REPLACE(sunshine,'---','') AS sunshine;

Datavals = FOREACH data GENERATE year,month,maxtemp,mintemp,frostday,rainfall,REPLACE(sunshine,'---','') AS sunshine;

Datavals1 = FOREACH Datavals GENERATE year,month,maxtemp,mintemp,frostday,rainfall,REPLACE(sunshine,'#','') AS sunshine;

Datavals2 = FOREACH Datavals1 GENERATE year,month,maxtemp,mintemp,frostday,rainfall,REPLACE(sunshine,'Provisional','') AS sunshine;

Datavals3 = FOREACH Datavals2 GENERATE year,month,maxtemp,mintemp,frostday,rainfall,REPLACE(sunshine,' ','') AS sunshine;

SortReadings = ORDER Datavals3 BY year ASC,month ASC;

STORE SortReadings INTO '/unit/airportclean' USING PigStorage(' ');

5. Pig python File(airport_udf.py)

@outputSchema("a_airport: {(year:float,month:float,maxtemp:float,mintemp:float,frostday:chararray,rainfall:chararray,sunshine:chararray)}")
def to_fahrenheit(km_airport):
	year,month,maxtemp,mintemp,frostday,rainfall,sunshine=km_airport.split(' ')
	maxtemp_l = float(maxtemp)*float(9/5)+32
	mintemp_l = float(mintemp)*float(9/5)+32
	return year,month, float(maxtemp_l), float(mintemp_l),frostday,rainfall,sunshine

hadoop fs -put /home/cloudera/Desktop/temp.py /unit/

6. Register Python with Pig

REGISTER 'hdfs:///unit/airport_udf.py' USING jython as convert_degree;
rowdata = LOAD '/unit/airportclean' AS (km_airport:chararray);
ConvFar =  FOREACH rowdata GENERATE FLATTEN(convert_degree.to_fahrenheit(km_airport));
STORE ConvFar INTO '/data/airportcleannew' USING PigStorage(' ');
DUMP ConvFar;

7. Create Hive Table(degreee)

Drop table if exists degreee;
create external table degreee(
year float,
month float,
maxtemp float,
mintemp float,
frostday float,
rainfall float,
sunshine float)
row format delimited fields terminated by ' '
Stored as textfile location '/unit/airportcleannew';

8. Hive Python File(mm_to_inches.py)

+#!/usr/bin/env python

import sys
import string

while True:
	line=sys.stdin.readline()
	if not line:
		break
	row=string.strip(line, "\n")
	year,month,maxtemp,mintemp,frostday,rainfall,sunshine= string.split(row, "\t")
	rainfall= float(rainfall)/25.4
	print "\t".join([year,month,maxtemp,mintemp,frostday,str(rainfall),sunshine])

hadoop fs -put /home/cloudera/Desktop/mm_to_inches.py /unit/

9. 
add file hdfs:///unit/mm_to_inches.py;
SELECT TRANSFORM(year,month,maxtemp,mintemp,frostday,rainfall,sunshine)
USING 'python mm_to_inches.py'
AS (year float,month float,maxtemp float,mintemp float,frostday float,rainfall float,sunshine float)
FROM degreee;


limit_data = LIMIT student_details 4; 
dump limit_data